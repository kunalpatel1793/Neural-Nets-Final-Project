{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A01T = h5py.File('/home/carla/Downloads/project_datasets/project_datasets/A01T_slice.mat','r')\n",
    "data = np.copy(A01T['image'])\n",
    "labels = np.copy(A01T['type'])\n",
    "labels = labels[0,0:data.shape[0]:1]\n",
    "labels = np.asarray(labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 25, 1000)\n",
      "(288,)\n",
      "(288, 1000, 25)\n",
      "(288,)\n"
     ]
    }
   ],
   "source": [
    "#check the data dimensionality\n",
    "print data.shape\n",
    "print labels.shape\n",
    "data = np.swapaxes(data, 1,2)\n",
    "print data.shape\n",
    "print labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 0 0 1 2 3 1 2 0 0 0 3 1 1 0 0 2 0 1 3 3 2 0 3 3 1 3 3 1 0 1 2 2 2 3\n",
      " 2 0 3 1 2 1 2 3 1 2 0 0 0 3 1 0 2 0 2 1 3 0 2 2 0 2 1 3 3 3 2 0 3 1 3 1 0\n",
      " 2 1 0 2 2 0 2 3 3 1 0 1 3 1 3 2 1 1 1 2 3 0 1 3 0 2 2 3 0 0 2 1 3 3 3 1 0\n",
      " 2 1 3 0 3 2 1 3 3 0 1 1 2 3 1 0 0 3 1 0 2 1 1 2 0 3 2 2 2 2 0 1 0 1 0 0 2\n",
      " 2 1 2 3 0 3 0 0 1 3 2 1 3 2 3 2 3 1 1 3 0 1 1 1 2 3 0 3 0 2 0 3 0 2 0 1 2\n",
      " 2 3 0 1 3 1 2 2 0 3 1 3 0 0 2 2 1 3 1 1 0 1 3 3 1 1 1 1 3 3 2 3 0 1 2 1 0\n",
      " 3 0 3 0 0 0 0 2 2 3 1 2 2 2 3 2 0 2 0 3 1 3 3 2 3 3 2 1 3 2 0 1 1 1 2 1 3\n",
      " 2 3 1 2 0 3 0 2 3 0 2 0 1 1 0 3 0 3 2 2 0 2 1 1 0 2 0 1 0]\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#one-hot-encode the data for use with categorical_crossentropy\n",
    "labels_cata = labels - 769\n",
    "print labels_cata\n",
    "labels_cata = to_categorical(labels_cata, num_classes=4)\n",
    "print labels_cata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 244 samples, validate on 44 samples\n",
      "Epoch 1/2\n",
      "244/244 [==============================] - 35s 145ms/step - loss: nan - acc: 0.2131 - val_loss: nan - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "244/244 [==============================] - 25s 102ms/step - loss: nan - acc: 0.2500 - val_loss: nan - val_acc: 0.2500\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_103 (LSTM)              (None, 5)                 620       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 24        \n",
      "=================================================================\n",
      "Total params: 644\n",
      "Trainable params: 644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#vanilla LSTM implementation\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape=(1000, 25), ))\n",
    "model.add(Dense(4, activation= 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(data, labels_cata, nb_epoch=2, batch_size=8, verbose=1, validation_split=0.15)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 259 samples, validate on 29 samples\n",
      "Epoch 1/3\n",
      "259/259 [==============================] - 74s 284ms/step - loss: nan - acc: 0.2896 - val_loss: nan - val_acc: 0.3448\n",
      "Epoch 2/3\n",
      "259/259 [==============================] - 64s 247ms/step - loss: nan - acc: 0.2394 - val_loss: nan - val_acc: 0.3448\n",
      "Epoch 3/3\n",
      "259/259 [==============================] - 61s 237ms/step - loss: nan - acc: 0.2394 - val_loss: nan - val_acc: 0.3448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c3b9610>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1000,25),return_sequences=True))\n",
    "model.add(LSTM(10, return_sequences=True))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(data, labels_cata, nb_epoch=3, batch_size=10, verbose=1, validation_split=0.1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 10s 10ms/step - loss: 11.6029 - acc: 0.1000 - val_loss: 11.4855 - val_acc: 0.0600\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 373us/step - loss: 11.6008 - acc: 0.0960 - val_loss: 11.4851 - val_acc: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 372us/step - loss: 11.6005 - acc: 0.0900 - val_loss: 11.4878 - val_acc: 0.0900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 11.6001 - acc: 0.1080 - val_loss: 11.4819 - val_acc: 0.0900\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 396us/step - loss: 11.5997 - acc: 0.1140 - val_loss: 11.4861 - val_acc: 0.0900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 11.5991 - acc: 0.1240 - val_loss: 11.4835 - val_acc: 0.0900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 11.5991 - acc: 0.1240 - val_loss: 11.4870 - val_acc: 0.0900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 389us/step - loss: 11.5986 - acc: 0.1130 - val_loss: 11.4866 - val_acc: 0.1000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 397us/step - loss: 11.5985 - acc: 0.1290 - val_loss: 11.4850 - val_acc: 0.0900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 11.5973 - acc: 0.1180 - val_loss: 11.4828 - val_acc: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160dd0c50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=10,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_42 (LSTM)               (None, 8, 32)             6272      \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 23,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Inputs: (None, 8, 16)\n",
      "Outputs: (None, 10)\n",
      "Actual input: (1000, 8, 16)\n",
      "Actual output: (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of the model and the inputs\n",
    "model.summary()\n",
    "print \"Inputs: {}\".format(model.input_shape)\n",
    "print \"Outputs: {}\".format(model.output_shape)\n",
    "print \"Actual input: {}\".format(x_train.shape)\n",
    "print \"Actual output: {}\".format(y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
