{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.layers import ConvLSTM2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import MaxPooling1D, Conv1D\n",
    "from keras.layers import GRU, LSTM, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Activation\n",
    "\n",
    "A01T = h5py.File('datasets/A01T_slice.mat','r')\n",
    "data = np.copy(A01T['image'])\n",
    "labels = np.copy(A01T['type'])\n",
    "labels = labels[0,0:data.shape[0]:1]\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "a = data[:56]\n",
    "b = data[57:]\n",
    "data = np.vstack((a,b))\n",
    "a = labels[:56]\n",
    "b = labels[57:]\n",
    "labels = np.hstack((a,b))\n",
    "#enc = OneHotEncoder()\n",
    "#enc_labels = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "enc_labels = to_categorical(labels-769, num_classes=4)\n",
    "print(enc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1000, 25, 1)\n",
      "(287, 1000, 25)\n"
     ]
    }
   ],
   "source": [
    "data2d = data.reshape(data.shape[0], data.shape[2], data.shape[1], 1)\n",
    "data1d = data.reshape(data.shape[0], data.shape[2], 25)\n",
    "print data2d.shape\n",
    "print data1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1000, 25, 1)\n",
      "(200, 1000, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "bs, t, f = data.shape\n",
    "np.random.seed(42)\n",
    "shuffle = np.random.choice(bs,bs,replace=False)\n",
    "\"\"\" \n",
    "train_samples = 200\n",
    "train_data = newdata[shuffle[:train_samples],:,:]\n",
    "train_labels = enc_labels[shuffle[:train_samples]]\n",
    "test_data = newdata[shuffle[train_samples:],:,:]\n",
    "test_labels = enc_labels[shuffle[train_samples:]]\n",
    "\n",
    "\"\"\"\n",
    "#mask = np.ones_like(data)\n",
    "#mask[[:,:,21:24]] = True\n",
    "#newdata = data[mask]\n",
    "#np.delete(mask, :,:,24)\n",
    "train_samples = 200\n",
    "train_data = data2d[shuffle[:train_samples],:,:]\n",
    "train_labels = enc_labels[shuffle[:train_samples]]\n",
    "test_data = data2d[shuffle[train_samples:],:,:]\n",
    "test_labels = enc_labels[shuffle[train_samples:]]\n",
    "print data2d.shape\n",
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_126 (Conv2D)          (None, 976, 25, 40)       1040      \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 976, 1, 40)        40040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 16, 1, 40)         0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 2564      \n",
      "=================================================================\n",
      "Total params: 43,644\n",
      "Trainable params: 43,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 150 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 4.8208 - acc: 0.2800 - val_loss: 1.9672 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 3s 21ms/step - loss: 3.5196 - acc: 0.2733 - val_loss: 1.7057 - val_acc: 0.2400\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 3s 23ms/step - loss: 1.9681 - acc: 0.3533 - val_loss: 1.7702 - val_acc: 0.2200\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 3s 23ms/step - loss: 1.2676 - acc: 0.4600 - val_loss: 1.5616 - val_acc: 0.1800\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 3s 22ms/step - loss: 1.0587 - acc: 0.5667 - val_loss: 1.4743 - val_acc: 0.2600\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 4s 23ms/step - loss: 1.0396 - acc: 0.5467 - val_loss: 1.4913 - val_acc: 0.2200\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 3s 21ms/step - loss: 0.9155 - acc: 0.6400 - val_loss: 1.4779 - val_acc: 0.2200\n",
      "Epoch 8/10\n",
      " 96/150 [==================>...........] - ETA: 1s - loss: 0.8464 - acc: 0.6562"
     ]
    }
   ],
   "source": [
    "# Conv2D + LSTM\n",
    "\"\"\"\n",
    "cnn = Sequential()\n",
    "cnn.add(ConvLSTM2D(1, (2,2), strides=2, activation='relu',input_shape=(1000, 5, 5, 1)))\n",
    "cnn.add(Flatten())\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = cnn.fit(train_data,train_labels,epochs=5,validation_split=0.25,batch_size=32)\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(40, kernel_size=(25,1), activation='relu', data_format='channels_last', input_shape=(1000, 25, 1)))  \n",
    "model.add(Conv2D(40, kernel_size=(1,25), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(60,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "hist = model.fit(train_data,train_labels,epochs=10,validation_split=0.25,batch_size=32)\n",
    "#test_score = model.evaluate(test_data, test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
