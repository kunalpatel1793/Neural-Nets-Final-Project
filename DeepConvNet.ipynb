{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Permute\n",
    "from keras.layers import ConvLSTM2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import MaxPooling1D, Conv1D\n",
    "from keras.layers import GRU, LSTM, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Activation\n",
    "\n",
    "A01T = h5py.File('datasets/A01T_slice.mat','r')\n",
    "data = np.copy(A01T['image'])\n",
    "labels = np.copy(A01T['type'])\n",
    "labels = labels[0,0:data.shape[0]:1]\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "a = data[:56]\n",
    "b = data[57:]\n",
    "data = np.vstack((a,b))\n",
    "a = labels[:56]\n",
    "b = labels[57:]\n",
    "labels = np.hstack((a,b))\n",
    "#enc = OneHotEncoder()\n",
    "#enc_labels = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "enc_labels = to_categorical(labels-769, num_classes=4)\n",
    "print(enc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1000, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "data2d = data.reshape(data.shape[0], data.shape[2], data.shape[1], 1)\n",
    "print data2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1000, 25, 1)\n",
      "(200, 1000, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "bs, t, f = data.shape\n",
    "np.random.seed(42)\n",
    "shuffle = np.random.choice(bs,bs,replace=False)\n",
    "\n",
    "#mask = np.ones_like(data)\n",
    "#mask[[:,:,21:24]] = True\n",
    "#newdata = data[mask]\n",
    "#np.delete(mask, :,:,24)\n",
    "train_samples = 200\n",
    "train_data = data2d[shuffle[:train_samples],:,:]\n",
    "train_labels = enc_labels[shuffle[:train_samples]]\n",
    "test_data = data2d[shuffle[train_samples:],:,:]\n",
    "test_labels = enc_labels[shuffle[train_samples:]]\n",
    "print data2d.shape\n",
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_258 (Conv2D)          (None, 981, 25, 15)       315       \n",
      "_________________________________________________________________\n",
      "conv2d_259 (Conv2D)          (None, 967, 6, 15)        67515     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_133 (MaxPoolin (None, 322, 6, 15)        0         \n",
      "_________________________________________________________________\n",
      "permute_55 (Permute)         (None, 322, 15, 6)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_260 (Conv2D)          (None, 303, 1, 30)        54030     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_134 (MaxPoolin (None, 101, 1, 30)        0         \n",
      "_________________________________________________________________\n",
      "permute_56 (Permute)         (None, 101, 30, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_261 (Conv2D)          (None, 82, 1, 60)         36060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_135 (MaxPoolin (None, 27, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "permute_57 (Permute)         (None, 27, 60, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_262 (Conv2D)          (None, 8, 1, 120)         144120    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_136 (MaxPoolin (None, 2, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 964       \n",
      "=================================================================\n",
      "Total params: 303,004\n",
      "Trainable params: 303,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 150 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 18s 121ms/step - loss: 1.5932 - acc: 0.2667 - val_loss: 1.3875 - val_acc: 0.1600\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 18s 122ms/step - loss: 1.3865 - acc: 0.2667 - val_loss: 1.3874 - val_acc: 0.1600\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 1.3862 - acc: 0.2667 - val_loss: 1.3877 - val_acc: 0.1600\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 1.3860 - acc: 0.2667 - val_loss: 1.3879 - val_acc: 0.1600\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 1.3860 - acc: 0.2667 - val_loss: 1.3881 - val_acc: 0.1600\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 1.3859 - acc: 0.2667 - val_loss: 1.3884 - val_acc: 0.1600\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 1.3857 - acc: 0.2667 - val_loss: 1.3886 - val_acc: 0.1600\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 1.3856 - acc: 0.2667 - val_loss: 1.3890 - val_acc: 0.1600\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 19s 127ms/step - loss: 1.3856 - acc: 0.2667 - val_loss: 1.3896 - val_acc: 0.1600\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 19s 129ms/step - loss: 1.3854 - acc: 0.2667 - val_loss: 1.3898 - val_acc: 0.1600\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=(20,1), activation='relu', data_format='channels_last', input_shape=(1000, 25, 1)))  \n",
    "model.add(Conv2D(15, kernel_size=(15,20), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(30, kernel_size=(20,15), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(60, kernel_size=(20,30), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(120, kernel_size=(20,60), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "hist = model.fit(train_data,train_labels,epochs=10,validation_split=0.25,batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
