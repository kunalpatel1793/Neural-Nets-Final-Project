{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import UtilNNDL as util\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Permute\n",
    "from keras.layers import ConvLSTM2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import MaxPooling1D, Conv1D\n",
    "from keras.layers import GRU, LSTM, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten, Reshape\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Activation\n",
    "\n",
    "A01T = h5py.File('datasets/A01T_slice.mat','r')\n",
    "data = np.copy(A01T['image'])\n",
    "labels = np.copy(A01T['type'])\n",
    "labels = labels[0,0:data.shape[0]:1]\n",
    "labels = np.asarray(labels, dtype=np.int32)\n",
    "\n",
    "a = data[:56]\n",
    "b = data[57:]\n",
    "data = np.vstack((a,b))\n",
    "data = data[:,:22,:]\n",
    "a = labels[:56]\n",
    "b = labels[57:]\n",
    "labels = np.hstack((a,b))\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2870, 22, 512) (2870,)\n",
      "(2870, 512, 22, 1)\n",
      "(2870, 4)\n"
     ]
    }
   ],
   "source": [
    "data2d_sliced, labels_sliced = util.create_window_data(data, labels)\n",
    "#util.plot_hist(data2d_sliced)\n",
    "print data2d_sliced.shape, labels_sliced.shape\n",
    "data2d = data2d_sliced.reshape(data2d_sliced.shape[0], data2d_sliced.shape[2], data2d_sliced.shape[1], 1)\n",
    "print data2d.shape\n",
    "\n",
    "#enc = OneHotEncoder()\n",
    "#enc_labels = enc.fit_transform(labels.reshape(-1,1)).toarray()\n",
    "enc_labels = to_categorical(labels_sliced-769, num_classes=4)\n",
    "print(enc_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2870, 512, 22, 1)\n",
      "(2820, 512, 22, 1)\n",
      "(50, 512, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "bs, t, n, c = data2d.shape\n",
    "np.random.seed(42)\n",
    "shuffle = np.random.choice(bs,bs,replace=False)\n",
    "\n",
    "#mask = np.ones_like(data)\n",
    "#mask[[:,:,21:24]] = True\n",
    "#newdata = data[mask]\n",
    "#np.delete(mask, :,:,24)\n",
    "train_samples = bs - 50\n",
    "train_data = data2d[shuffle[:train_samples],:,:]\n",
    "train_labels = enc_labels[shuffle[:train_samples]]\n",
    "test_data = data2d[shuffle[train_samples:],:,:]\n",
    "test_labels = enc_labels[shuffle[train_samples:]]\n",
    "print data2d.shape\n",
    "print train_data.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_136 (Conv2D)          (None, 498, 22, 15)       240       \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 484, 8, 15)        50640     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 161, 8, 15)        0         \n",
      "_________________________________________________________________\n",
      "permute_82 (Permute)         (None, 161, 15, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 152, 1, 30)        36030     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_110 (MaxPoolin (None, 50, 1, 30)         0         \n",
      "_________________________________________________________________\n",
      "permute_83 (Permute)         (None, 50, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 41, 1, 60)         18060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_111 (MaxPoolin (None, 13, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "permute_84 (Permute)         (None, 13, 60, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 4, 1, 120)         72120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 120, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 120, 32)           4352      \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 184,710\n",
      "Trainable params: 184,678\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Train on 1410 samples, validate on 1410 samples\n",
      "Epoch 1/10\n",
      "1410/1410 [==============================] - 135s 96ms/step - loss: 1.3806 - acc: 0.2716 - val_loss: 1.6073 - val_acc: 0.2376\n",
      "Epoch 2/10\n",
      "1410/1410 [==============================] - 129s 92ms/step - loss: 1.3142 - acc: 0.3496 - val_loss: 2.9054 - val_acc: 0.2546\n",
      "Epoch 3/10\n",
      "1410/1410 [==============================] - 128s 91ms/step - loss: 1.1348 - acc: 0.4404 - val_loss: 2.9685 - val_acc: 0.3305\n",
      "Epoch 4/10\n",
      "1410/1410 [==============================] - 120s 85ms/step - loss: 1.0393 - acc: 0.4681 - val_loss: 3.4855 - val_acc: 0.2567\n",
      "Epoch 5/10\n",
      "1410/1410 [==============================] - 117s 83ms/step - loss: 1.0429 - acc: 0.4887 - val_loss: 2.5352 - val_acc: 0.2816\n",
      "Epoch 6/10\n",
      "1410/1410 [==============================] - 127s 90ms/step - loss: 0.9532 - acc: 0.5348 - val_loss: 1.8410 - val_acc: 0.3716\n",
      "Epoch 7/10\n",
      "1410/1410 [==============================] - 118s 83ms/step - loss: 0.9104 - acc: 0.5475 - val_loss: 1.5160 - val_acc: 0.3929\n",
      "Epoch 8/10\n",
      "1410/1410 [==============================] - 117s 83ms/step - loss: 0.8697 - acc: 0.5709 - val_loss: 1.5120 - val_acc: 0.4035\n",
      "Epoch 9/10\n",
      "1410/1410 [==============================] - 128s 91ms/step - loss: 0.8330 - acc: 0.5908 - val_loss: 2.7397 - val_acc: 0.3468\n",
      "Epoch 10/10\n",
      "1410/1410 [==============================] - 123s 88ms/step - loss: 0.9271 - acc: 0.5411 - val_loss: 4.2329 - val_acc: 0.2553\n"
     ]
    }
   ],
   "source": [
    "num_filters = 15\n",
    "model = Sequential()\n",
    "model.add(Conv2D(num_filters, kernel_size=(num_filters,1), activation='relu', data_format='channels_last', input_shape=(data2d.shape[1], data2d.shape[2], data2d.shape[3])))  \n",
    "model.add(Conv2D(num_filters, kernel_size=(15,num_filters), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(num_filters*2, kernel_size=(10,num_filters), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(num_filters*4, kernel_size=(10,num_filters*2), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(num_filters*8, kernel_size=(10,num_filters*4), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Reshape((num_filters*8,1)))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "#model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "hist = model.fit(train_data,train_labels,epochs=10,validation_split=0.25,batch_size=32)\n",
    "#model.test_on_batch(test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_91 (Conv2D)           (None, 503, 25, 15)       165       \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 489, 16, 15)       33765     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 163, 16, 15)       0         \n",
      "_________________________________________________________________\n",
      "permute_55 (Permute)         (None, 163, 15, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 154, 1, 30)        72030     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 51, 1, 30)         0         \n",
      "_________________________________________________________________\n",
      "permute_56 (Permute)         (None, 51, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 42, 1, 60)         18060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 14, 1, 60)         0         \n",
      "_________________________________________________________________\n",
      "permute_57 (Permute)         (None, 14, 60, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 5, 1, 120)         72120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 1, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 120, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 120, 32)           4352      \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 203,760\n",
      "Trainable params: 203,728\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Train on 37 samples, validate on 13 samples\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 6s 176ms/step - loss: 1.3865 - acc: 0.2973 - val_loss: 1.4103 - val_acc: 0.2308\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 1.3630 - acc: 0.2973 - val_loss: 2.4929 - val_acc: 0.1538\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 1.3713 - acc: 0.2973 - val_loss: 2.5123 - val_acc: 0.1538\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 1.3564 - acc: 0.3243 - val_loss: 3.6421 - val_acc: 0.1538\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.3203 - acc: 0.5135 - val_loss: 6.1312 - val_acc: 0.1538\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.2366 - acc: 0.4865 - val_loss: 5.8568 - val_acc: 0.1538\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.2458 - acc: 0.3784 - val_loss: 2.9214 - val_acc: 0.1538\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.1667 - acc: 0.5405 - val_loss: 1.5044 - val_acc: 0.3077\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 3s 85ms/step - loss: 1.0944 - acc: 0.6216 - val_loss: 1.5844 - val_acc: 0.3846\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 1.0714 - acc: 0.6216 - val_loss: 1.9595 - val_acc: 0.3077\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=(10,1), activation='relu', data_format='channels_last', input_shape=(data2d.shape[1], data2d.shape[2], data2d.shape[3])))  \n",
    "model.add(Conv2D(15, kernel_size=(15,10), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(30, kernel_size=(10,15), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(60, kernel_size=(10,30), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Permute((1,3,2)))\n",
    "\n",
    "model.add(Conv2D(120, kernel_size=(10,60), activation='relu') ) \n",
    "model.add(MaxPooling2D(pool_size=(3,1)))\n",
    "model.add(Reshape((120,1)))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "#model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n",
    "hist = model.fit(train_data,train_labels,epochs=10,validation_split=0.25,batch_size=32)\n",
    "#model.test_on_batch(test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
